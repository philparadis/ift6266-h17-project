{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: TITAN X (Pascal) (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Mar 15 14:54:01 2017\n",
    "\n",
    "@author: paradiph\n",
    "\"\"\"\n",
    "\n",
    "import os, sys\n",
    "import glob\n",
    "import cPickle as pkl\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "#from skimage.transform import resize\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras.utils import plot_model\n",
    "\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment name = exp_arch-mlp_loss-mse_activation-sigmoid_epochs-50\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "# Run experiments here\n",
    "# Define your global options and experiment name\n",
    "# Then run the desired model\n",
    "#################################################\n",
    "\n",
    "### The experiment name is very important.\n",
    "\n",
    "## Your model will be saved in:                           models/<experiment_name>.h5\n",
    "## A summary of your model architecture will saved be in: models/summary_<experiment_name>.txt\n",
    "## Your model's performance will be saved in:             models/performance_<experiment_name>.txt\n",
    "\n",
    "## Your predictions will be saved in: predictions/assets/<experiment_name>/Y_pred_<i>.jpg\n",
    "##                                    predictions/assets/<experiment_name>/Y_<i>.jpg\n",
    "##                                    predictions/assets/<experiment_name>/X_outer_<i>.jpg\n",
    "##                                    predictions/assets/<experiment_name>/X_full_<i>.jpg\n",
    "##                                    predictions/assets/<experiment_name>/X_full_pred_<i>.jpg\n",
    "\n",
    "#experiment_name = \"exp2_mlp_msa_nodropout\"\n",
    "#experiment_name = \"exp3_mlp_mse_sigmoid_final_layer\"\n",
    "#TODO: Which ever first 3 experiments work best, repeat it with msa instead of mse. i.e. experiment_name = \"exp4_mlp_msa_sigmoid_final_layer\"\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "architecture = 'mlp'\n",
    "loss_function = 'mse'\n",
    "#loss_function = 'mae'\n",
    "use_dropout = False\n",
    "use_sigmoid_final_layer = True\n",
    "\n",
    "experiment_name = \"exp_arch-%s_loss-%s_activation-%s_epochs-%i\" % (architecture, \\\n",
    "    loss_function, \"sigmoid\" if use_sigmoid_final_layer else \"relu\", num_epochs)\n",
    "\n",
    "print(\"Experiment name = %s\" % experiment_name)\n",
    "\n",
    "### Fixed variables: DO NOT CHANGE THOSE\n",
    "input_dim = 64*64*3 - 32*32*3\n",
    "output_dim = 32*32*3\n",
    "path_mscoco=\"datasets/mscoco_inpainting/inpainting/\"\n",
    "path_traindata=\"train2014\"\n",
    "path_caption_dict=\"dict_key_imgID_value_caps_train_and_valid.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### State variables: DO NOT EDIT\n",
    "### ONLY RUN THIS CELL IF YOU WANNA RESET EVERYTHING AND RELOAD THE DATA, RETRAIN THE MODEL, ETC.\n",
    "\n",
    "is_dataset_loaded = False\n",
    "is_model_trained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "# Info about the dataset\n",
    "#######################################\n",
    "# The data is already split into training and validation datasets\n",
    "# The training dataset has:\n",
    "# - 82782 items\n",
    "# - 984 MB of data\n",
    "# The validation dataset has:\n",
    "# - 40504 items\n",
    "# - 481 MB of data\n",
    "#\n",
    "# There is also a pickled dictionary that maps image filenames (minutes the\n",
    "# .jpg extension) to a list of 5 strings (the 5 human-generated captions).\n",
    "# This dictionary is an OrderedDict with 123286 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Utilities functions\n",
    "\n",
    "## Your model will be saved in:                           models/<experiment_name>.h5\n",
    "## A summary of your model architecture will saved be in: models/summary_<experiment_name>.txt\n",
    "## Your model's performance will be saved in:             models/performance_<experiment_name>.txt\n",
    "def save_model_info(exp_name, model):\n",
    "    out_dir = \"models/\"\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "        \n",
    "    model.save(os.path.join(out_dir, exp_name + '.h5')) \n",
    "    \n",
    "    #plot_model(model, to_file=os.path.join('model/', 'architecture_' + exp_name + '.png'), show_shapes=True)\n",
    "    \n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = open(os.path.join(out_dir, 'summary_' + exp_name + '.txt'), 'w')\n",
    "    model.summary()\n",
    "    sys.stdout = old_stdout\n",
    "\n",
    "    with open(os.path.join(out_dir, 'performance_' + exp_name + '.txt'), 'w') as fd:\n",
    "        # evaluate the model\n",
    "        scores = model.evaluate(X_train, Y_train, batch_size=batch_size)\n",
    "        fd.write(\"Training score %s: %.4f\\n\" % (model.metrics_names[1], scores[1]))\n",
    "        scores = model.evaluate(X_test, Y_test, batch_size=batch_size)\n",
    "        fd.write(\"Testing score %s: %.4f\\n\" % (model.metrics_names[1], scores[1]))\n",
    "        \n",
    "## Your predictions will be saved in: predictions/assets/<experiment_name>/Y_pred_<i>.jpg\n",
    "##                                    predictions/assets/<experiment_name>/Y_<i>.jpg\n",
    "##                                    predictions/assets/<experiment_name>/X_outer_<i>.jpg\n",
    "##                                    predictions/assets/<experiment_name>/X_full_<i>.jpg\n",
    "##                                    predictions/assets/<experiment_name>/X_full_pred_<i>.jpg\n",
    "def save_predictions_info(exp_name, pred, pred_indices, dataset,\n",
    "                          num_images = 10, show_images = False, use_flattened_datasets = True):\n",
    "    if use_flattened_datasets:\n",
    "        out_dir = os.path.join('predictions/', \"assets/\", exp_name)\n",
    "        if not os.path.exists(out_dir):\n",
    "            print(\"Creating new directory to save predictions results: \" + out_dir)\n",
    "            os.makedirs(out_dir)\n",
    "        else:\n",
    "            print(\"Overwriting previously saved prediction results in directory: \" + out_dir)\n",
    "            \n",
    "        for row in range(num_images):\n",
    "            idt = pred_indices[row]\n",
    "            Image.fromarray(dataset.images_outer2d[idt]).save(os.path.join(out_dir, 'images_outer2d_' + str(row) + '.jpg'))\n",
    "            #img.show()\n",
    "\n",
    "            Image.fromarray(pred[row]).save(os.path.join(out_dir, 'images_pred_' + str(row) + '.jpg'))\n",
    "            #img.show()\n",
    "\n",
    "            Image.fromarray(dataset.images_inner2d[idt]).save(os.path.join(out_dir, 'images_inner2d_' + str(row) + '.jpg'))\n",
    "            #img.show()\n",
    "\n",
    "            Image.fromarray(dataset.images[idt]).save(os.path.join(out_dir, 'fullimages_' + str(row) + '.jpg'))\n",
    "            #fullimg.show()\n",
    "\n",
    "            fullimg_pred = np.copy(dataset.images[idt])\n",
    "            center = (int(np.floor(fullimg_pred.shape[0] / 2.)), int(np.floor(fullimg_pred.shape[1] / 2.)))\n",
    "            fullimg_pred[center[0]-16:center[0]+16, center[1]-16:center[1]+16, :] = pred[row, :, :, :]\n",
    "            Image.fromarray(fullimg_pred).save(os.path.join(out_dir, 'fullimages_pred_' + str(row) + '.jpg'))\n",
    "            #img.show()\n",
    "\n",
    "def print_results_as_html(exp_name, pred, dataset, num_images=10):    \n",
    "    html_dir = os.path.join(\"predictions/\")\n",
    "    img_src = os.path.join(\"assets/\", exp_name)\n",
    "    path_html = os.path.join(html_dir, \"results_\" + exp_name + \".html\")\n",
    "    print(\"Saving results as html to: \" + path_html)\n",
    "\n",
    "    with open(path_html, 'w') as fd:\n",
    "        fd.write(\"\"\"\n",
    "<table>\n",
    "  <tr>\n",
    "    <th style=\"width:132px\">Input</th>\n",
    "    <th style=\"width:68px\">Model prediction</th>\n",
    "    <th style=\"width:68px\">Correct output</th> \n",
    "    <th style=\"width:132px\">Input + prediction</th>\n",
    "    <th style=\"width:132px\">Input + correct output</th>\n",
    "  </tr>\n",
    "\"\"\")\n",
    "\n",
    "        for row in range(num_images):\n",
    "            fd.write(\"  <tr>\\n\")\n",
    "            fd.write(\"    <td><img src='%s/images_outer2d_%i.jpg' width='128' height='128'></td>\\n\" % (img_src, row))\n",
    "            fd.write(\"    <td><img src='%s/images_pred_%i.jpg' width='64' height='64'></td>\\n\" % (img_src, row))\n",
    "            fd.write(\"    <td><img src='%s/images_inner2d_%i.jpg' width='64' height='64'></td>\\n\" % (img_src, row))\n",
    "            fd.write(\"    <td><img src='%s/fullimages_pred_%i.jpg' width='128' height='128'></td>\\n\" % (img_src, row))\n",
    "            fd.write(\"    <td><img src='%s/fullimages_%i.jpg' width='128' height='128'></td>\\n\" % (img_src, row))\n",
    "            fd.write('</tr>\\n')\n",
    "        \n",
    "        fd.write('</table>')\n",
    "\n",
    "def normalize_data(data):\n",
    "    data = data.astype('float32')\n",
    "    data /= 255\n",
    "    return data\n",
    "\n",
    "def denormalize_data(data):\n",
    "    data *= 255\n",
    "    data = data.astype('uint8')\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Define the main class for handling our dataset called InpaintingDataset\n",
    "\n",
    "class InpaintingDataset(object):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.images = []\n",
    "        self.images_outer2d = []\n",
    "        self.images_inner2d = []\n",
    "        self.images_outer_flat = []\n",
    "        self.images_inner_flat = []\n",
    "        self.captions_ids = []\n",
    "        self.captions_dict = []\n",
    "        self._is_dataset_loaded = False\n",
    "        self._is_flattened = False\n",
    "        self._is_normalized = False\n",
    "        self._num_rows = None\n",
    "    \n",
    "    def normalize(self):\n",
    "        if self._is_normalized:\n",
    "            print(\"WARNING: Attempting to normalize already normalized dataset... Ignoring this call...\")\n",
    "            return\n",
    "        self.images_outer_flat = normalize_data(self.images_outer_flat)\n",
    "        self.images_inner_flat = normalize_data(self.images_inner_flat)\n",
    "        self._is_normalized = True\n",
    "\n",
    "    def denormalize(self):\n",
    "        if not self._is_normalized:\n",
    "            print(\"WARNING: Attempting to denormalize already denormalized dataset... Ignoring this call...\")\n",
    "            return\n",
    "        self.images_outer_flat = denormalize_data(self.images_outer_flat)\n",
    "        self.images_inner_flat = denormalize_data(self.images_inner_flat)\n",
    "        self._is_normalized = False\n",
    "    \n",
    "    def load_jpgs_and_captions_and_flatten(self, paths_list, caption_path, force_reload = False):\n",
    "        with open(caption_path) as fd:\n",
    "            caption_dict = pkl.load(fd)\n",
    "        if not self._is_dataset_loaded and not force_reload:\n",
    "            images = []\n",
    "            images_outer2d = []\n",
    "            images_inner2d = []\n",
    "            images_outer_flat = []\n",
    "            images_inner_flat = []\n",
    "            captions_ids = []\n",
    "            captions_dict = []\n",
    "            for i, img_path in enumerate(paths_list):\n",
    "                img = Image.open(img_path)\n",
    "                img_array = np.array(img)\n",
    "\n",
    "                # File names look like this: COCO_train2014_000000520978.jpg\n",
    "                cap_id = os.path.basename(img_path)[:-4]\n",
    "\n",
    "                ### Get input/target from the images\n",
    "                center = (int(np.floor(img_array.shape[0] / 2.)), int(np.floor(img_array.shape[1] / 2.)))\n",
    "                if len(img_array.shape) == 3:\n",
    "                    image = np.copy(img_array)\n",
    "\n",
    "                    outer_2d = np.copy(img_array)\n",
    "                    outer_2d[center[0]-16:center[0]+16, center[1]-16:center[1]+16, :] = 0\n",
    "\n",
    "                    outer = np.copy(img_array)\n",
    "                    outer_mask = np.array(np.ones(np.shape(img_array)), dtype='bool')\n",
    "                    outer_mask[center[0]-16:center[0]+16, center[1]-16:center[1]+16, :] = False\n",
    "                    outer_flat = outer.flatten()\n",
    "                    outer_mask_flat = outer_mask.flatten()\n",
    "                    outer_flat = outer_flat[outer_mask_flat]\n",
    "\n",
    "                    inner2d = np.copy(img_array)\n",
    "                    inner2d = inner2d[center[0]-16:center[0]+16, center[1] - 16:center[1]+16, :]\n",
    "\n",
    "                    inner = np.copy(img_array)\n",
    "                    inner = inner[center[0]-16:center[0]+16, center[1] - 16:center[1]+16, :]\n",
    "                    inner_flat = inner.flatten()\n",
    "                else:\n",
    "                    # For now, ignore greyscale images\n",
    "                    continue\n",
    "                    #X_outer = np.copy(img_array)\n",
    "                    #X_outer[center[0]-16:center[0]+16, center[1]-16:center[1]+16] = 0\n",
    "                    #X_inner = img_array[center[0]-16:center[0]+16, center[1] - 16:center[1]+16]\n",
    "\n",
    "\n",
    "                #Image.fromarray(img_array).show()\n",
    "                images.append(image)\n",
    "                images_outer2d.append(outer_2d)\n",
    "                images_inner2d.append(inner2d)\n",
    "                images_outer_flat.append(outer_flat)\n",
    "                images_inner_flat.append(inner_flat)\n",
    "                captions_ids.append(cap_id)\n",
    "                captions_dict.append(caption_dict[cap_id])\n",
    "                \n",
    "                if i % 10000 == 0:\n",
    "                    print(\"Loaded image #%i\" % i)\n",
    "\n",
    "            self.images = np.array(images)\n",
    "            self.images_inner_flat = np.array(images_inner_flat)\n",
    "            self.images_outer_flat = np.array(images_outer_flat)\n",
    "            self.images_outer2d = np.array(images_outer2d)\n",
    "            self.images_inner2d = np.array(images_inner2d)\n",
    "            self.captions_ids = np.array(captions_ids)\n",
    "            self.captions_dict = np.array(captions_dict)\n",
    "\n",
    "            self._is_flattened = True\n",
    "            self._is_dataset_loaded = True\n",
    "            self._num_rows = self.images.shape[0]\n",
    "        else:\n",
    "            print(\"Dataset is already loaded. Skipping this call. Please pass the argument force_reload=True to force reloading of dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Create and initialize an empty InpaintingDataset object\n",
    "Dataset = InpaintingDataset(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images paths from: datasets/mscoco_inpainting/inpainting/train2014/*.jpg\n",
      "Found 82782 image paths.\n",
      "Loading images data into memory and performing some pre-processing...\n",
      "Loaded image #0\n",
      "Loaded image #10000\n",
      "Loaded image #20000\n",
      "Loaded image #30000\n",
      "Loaded image #40000\n",
      "Loaded image #50000\n",
      "Loaded image #60000\n",
      "Loaded image #70000\n",
      "Loaded image #80000\n",
      "Finished loading and pre-processing datasets...\n",
      "Summary of datasets:\n",
      "images.shape            = (82611, 64, 64, 3)\n",
      "images_outer2d.shape    = (82611, 64, 64, 3)\n",
      "images_inner2d.shape    = (82611, 32, 32, 3)\n",
      "images_outer_flat.shape = (82611, 9216)\n",
      "images_inner_flat.shape = (82611, 3072)\n",
      "captions_ids.shape      = (82611,)\n",
      "captions_dict.shape     = (82611,)\n"
     ]
    }
   ],
   "source": [
    "### Load training images and captions\n",
    "\n",
    "# Get captions dictionary path\n",
    "caption_path = os.path.join(path_mscoco, path_caption_dict)\n",
    "    \n",
    "# Get a list of all training images full filename paths\n",
    "data_path = os.path.join(path_mscoco, path_traindata)\n",
    "print(\"Loading images paths from: \" + data_path + \"/*.jpg\")\n",
    "train_images_paths = glob.glob(data_path + \"/*.jpg\")\n",
    "print(\"Found %i image paths.\" % len(train_images_paths))\n",
    "print(\"Loading images data into memory and performing some pre-processing...\")\n",
    "Dataset.load_jpgs_and_captions_and_flatten(train_images_paths, caption_path)\n",
    "\n",
    "print(\"Finished loading and pre-processing datasets...\")\n",
    "print(\"Summary of datasets:\")\n",
    "print(\"images.shape            = \" + str(Dataset.images.shape))\n",
    "print(\"images_outer2d.shape    = \" + str(Dataset.images_outer2d.shape))\n",
    "print(\"images_inner2d.shape    = \" + str(Dataset.images_inner2d.shape))\n",
    "print(\"images_outer_flat.shape = \" + str(Dataset.images_outer_flat.shape))\n",
    "print(\"images_inner_flat.shape = \" + str(Dataset.images_inner_flat.shape))\n",
    "print(\"captions_ids.shape      = \" + str(Dataset.captions_ids.shape))\n",
    "print(\"captions_dict.shape     = \" + str(Dataset.captions_dict.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Sanity check:\n",
    "#print(\"Performing sanity check using first 10 elements of first 3 rows:\")\n",
    "#sanity_check_values = np.array([[57,   69,  57,  65,  79,  56,  63,  81,  43,  53],\n",
    "#                                [197, 202, 195, 167, 164, 147, 104,  87,  57, 102],\n",
    "#                                [104, 100,  97,  77,  80,  53, 172, 181, 128, 242]])\n",
    "#for i in range(3):\n",
    "#    top10 = Dataset.images_inner_flat[i, range(10)]\n",
    "#    print(top10)\n",
    "#    np.testing.assert_array_equal(top10, sanity_check_values[i])\n",
    "#    print(\"Row \" + str(i) + \" passed sanity check!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/paradiph/anaconda2/envs/keras/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset into training and testing sets with shuffling...\n",
      "Splitting dataset into training and testing sets with shuffling...\n",
      "X_train.shape = (66088, 9216)\n",
      "X_test.shape  = (16523, 9216)\n",
      "Y_train.shape = (66088, 3072)\n",
      "Y_test.shape  = (16523, 3072)\n",
      "id_train.shape = (66088,)\n",
      "id_test.shape  = (16523,)\n"
     ]
    }
   ],
   "source": [
    "### Normalize datasets\n",
    "Dataset.normalize()\n",
    "\n",
    "### Split into training and testing data\n",
    "from sklearn.cross_validation import train_test_split\n",
    "num_rows = Dataset.images.shape[0]\n",
    "indices = np.arange(num_rows)\n",
    "id_train, id_test = train_test_split(indices,\n",
    "                                     test_size=0.20,\n",
    "                                     random_state=1)\n",
    "\n",
    "### Generating the training and testing datasets (80%/20% train/test split)\n",
    "print(\"Splitting dataset into training and testing sets with shuffling...\")\n",
    "X_train, X_test, Y_train, Y_test = Dataset.images_outer_flat[id_train], \\\n",
    "                                   Dataset.images_outer_flat[id_test], \\\n",
    "                                   Dataset.images_inner_flat[id_train], \\\n",
    "                                   Dataset.images_inner_flat[id_test]\n",
    "\n",
    "print(\"Splitting dataset into training and testing sets with shuffling...\")\n",
    "print(\"X_train.shape = \" + str(X_train.shape))\n",
    "print(\"X_test.shape  = \" + str(X_test.shape))\n",
    "print(\"Y_train.shape = \" + str(Y_train.shape))\n",
    "print(\"Y_test.shape  = \" + str(Y_test.shape))\n",
    "print(\"id_train.shape = \" + str(id_train.shape))\n",
    "print(\"id_test.shape  = \" + str(id_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_train = [17442 21862  2835 ..., 50057  5192 77708]\n",
      "id_test  = [40977 36857 38411 ..., 77626 38615 14749]\n",
      "Y_train.shape = (66088, 3072)\n",
      "Y_train[0,1500:1550] = \n",
      "[ 0.38039216  0.35294119  0.25098041  0.40392157  0.3764706   0.27450982\n",
      "  0.44705883  0.41960785  0.31764707  0.48235294  0.45490196  0.35294119\n",
      "  0.50196081  0.47450981  0.37254903  0.48627451  0.45882353  0.35686275\n",
      "  0.4627451   0.43529412  0.33333334  0.43921569  0.41176471  0.30980393\n",
      "  0.42352942  0.39607844  0.29411766  0.41960785  0.39215687  0.29019609\n",
      "  0.42352942  0.39607844  0.29411766  0.42745098  0.40000001  0.29803923\n",
      "  0.42352942  0.40000001  0.30588236  0.40000001  0.3764706   0.28235295\n",
      "  0.39607844  0.37254903  0.27843139  0.41176471  0.3882353   0.29411766\n",
      "  0.40392157  0.38039216]\n"
     ]
    }
   ],
   "source": [
    "### Sanity check:\n",
    "print(\"id_train = \" + str(id_train))\n",
    "print(\"id_test  = \" + str(id_test))\n",
    "print(\"Y_train.shape = \" + str(Y_train.shape))\n",
    "print(\"Y_train[0,1500:1550] = \\n\" + str(Y_train[0,1500:1550]))\n",
    "\n",
    "idx = id_train[0]\n",
    "img = Image.fromarray(Dataset.images[0])\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "is_model_trained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MLP model...\n",
      "Model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               4719104   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3072)              1575936   \n",
      "=================================================================\n",
      "Total params: 6,557,696.0\n",
      "Trainable params: 6,557,696.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Compiling model...\n",
      "Fitting model...\n",
      "Train on 66088 samples, validate on 16523 samples\n",
      "Epoch 1/50\n",
      "6s - loss: 0.0462 - mean_squared_error: 0.0462 - val_loss: 0.0390 - val_mean_squared_error: 0.0390\n",
      "Epoch 2/50\n",
      "6s - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0366 - val_mean_squared_error: 0.0366\n",
      "Epoch 3/50\n",
      "6s - loss: 0.0369 - mean_squared_error: 0.0369 - val_loss: 0.0376 - val_mean_squared_error: 0.0376\n",
      "Epoch 4/50\n",
      "6s - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.0361 - val_mean_squared_error: 0.0361\n",
      "Epoch 5/50\n",
      "6s - loss: 0.0359 - mean_squared_error: 0.0359 - val_loss: 0.0367 - val_mean_squared_error: 0.0367\n",
      "Epoch 6/50\n",
      "6s - loss: 0.0355 - mean_squared_error: 0.0355 - val_loss: 0.0370 - val_mean_squared_error: 0.0370\n",
      "Epoch 7/50\n",
      "6s - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0353 - val_mean_squared_error: 0.0353\n",
      "Epoch 8/50\n",
      "6s - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0362 - val_mean_squared_error: 0.0362\n",
      "Epoch 9/50\n",
      "6s - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.0360 - val_mean_squared_error: 0.0360\n",
      "Epoch 10/50\n",
      "6s - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.0354 - val_mean_squared_error: 0.0354\n",
      "Epoch 11/50\n",
      "6s - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0351 - val_mean_squared_error: 0.0351\n",
      "Epoch 12/50\n",
      "6s - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0355 - val_mean_squared_error: 0.0355\n",
      "Epoch 13/50\n",
      "6s - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0350 - val_mean_squared_error: 0.0350\n",
      "Epoch 14/50\n",
      "6s - loss: 0.0343 - mean_squared_error: 0.0343 - val_loss: 0.0350 - val_mean_squared_error: 0.0350\n",
      "Epoch 15/50\n",
      "6s - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.0352 - val_mean_squared_error: 0.0352\n",
      "Epoch 16/50\n",
      "6s - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0349 - val_mean_squared_error: 0.0349\n",
      "Epoch 17/50\n",
      "6s - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.0350 - val_mean_squared_error: 0.0350\n",
      "Epoch 18/50\n",
      "6s - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0355 - val_mean_squared_error: 0.0355\n",
      "Epoch 19/50\n",
      "6s - loss: 0.0337 - mean_squared_error: 0.0337 - val_loss: 0.0353 - val_mean_squared_error: 0.0353\n",
      "Epoch 20/50\n",
      "6s - loss: 0.0336 - mean_squared_error: 0.0336 - val_loss: 0.0355 - val_mean_squared_error: 0.0355\n",
      "Epoch 21/50\n",
      "6s - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0356 - val_mean_squared_error: 0.0356\n",
      "Epoch 22/50\n",
      "6s - loss: 0.0334 - mean_squared_error: 0.0334 - val_loss: 0.0351 - val_mean_squared_error: 0.0351\n",
      "Epoch 23/50\n",
      "6s - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0358 - val_mean_squared_error: 0.0358\n",
      "Epoch 24/50\n",
      "6s - loss: 0.0332 - mean_squared_error: 0.0332 - val_loss: 0.0356 - val_mean_squared_error: 0.0356\n",
      "Epoch 25/50\n",
      "6s - loss: 0.0331 - mean_squared_error: 0.0331 - val_loss: 0.0351 - val_mean_squared_error: 0.0351\n",
      "Epoch 26/50\n",
      "6s - loss: 0.0330 - mean_squared_error: 0.0330 - val_loss: 0.0354 - val_mean_squared_error: 0.0354\n",
      "Epoch 27/50\n",
      "6s - loss: 0.0329 - mean_squared_error: 0.0329 - val_loss: 0.0361 - val_mean_squared_error: 0.0361\n",
      "Epoch 28/50\n",
      "7s - loss: 0.0328 - mean_squared_error: 0.0328 - val_loss: 0.0354 - val_mean_squared_error: 0.0354\n",
      "Epoch 29/50\n",
      "6s - loss: 0.0327 - mean_squared_error: 0.0327 - val_loss: 0.0356 - val_mean_squared_error: 0.0356\n",
      "Epoch 30/50\n",
      "6s - loss: 0.0327 - mean_squared_error: 0.0327 - val_loss: 0.0356 - val_mean_squared_error: 0.0356\n",
      "Epoch 31/50\n",
      "6s - loss: 0.0325 - mean_squared_error: 0.0325 - val_loss: 0.0353 - val_mean_squared_error: 0.0353\n",
      "Epoch 32/50\n",
      "6s - loss: 0.0325 - mean_squared_error: 0.0325 - val_loss: 0.0352 - val_mean_squared_error: 0.0352\n",
      "Epoch 33/50\n",
      "6s - loss: 0.0323 - mean_squared_error: 0.0323 - val_loss: 0.0355 - val_mean_squared_error: 0.0355\n",
      "Epoch 34/50\n",
      "6s - loss: 0.0323 - mean_squared_error: 0.0323 - val_loss: 0.0361 - val_mean_squared_error: 0.0361\n",
      "Epoch 35/50\n",
      "6s - loss: 0.0322 - mean_squared_error: 0.0322 - val_loss: 0.0354 - val_mean_squared_error: 0.0354\n",
      "Epoch 36/50\n",
      "6s - loss: 0.0321 - mean_squared_error: 0.0321 - val_loss: 0.0362 - val_mean_squared_error: 0.0362\n",
      "Epoch 37/50\n",
      "6s - loss: 0.0320 - mean_squared_error: 0.0320 - val_loss: 0.0358 - val_mean_squared_error: 0.0358\n",
      "Epoch 38/50\n",
      "6s - loss: 0.0319 - mean_squared_error: 0.0319 - val_loss: 0.0356 - val_mean_squared_error: 0.0356\n",
      "Epoch 39/50\n",
      "6s - loss: 0.0319 - mean_squared_error: 0.0319 - val_loss: 0.0356 - val_mean_squared_error: 0.0356\n",
      "Epoch 40/50\n",
      "6s - loss: 0.0318 - mean_squared_error: 0.0318 - val_loss: 0.0362 - val_mean_squared_error: 0.0362\n",
      "Epoch 41/50\n",
      "6s - loss: 0.0317 - mean_squared_error: 0.0317 - val_loss: 0.0358 - val_mean_squared_error: 0.0358\n",
      "Epoch 42/50\n",
      "6s - loss: 0.0317 - mean_squared_error: 0.0317 - val_loss: 0.0358 - val_mean_squared_error: 0.0358\n",
      "Epoch 43/50\n",
      "6s - loss: 0.0316 - mean_squared_error: 0.0316 - val_loss: 0.0363 - val_mean_squared_error: 0.0363\n",
      "Epoch 44/50\n",
      "6s - loss: 0.0315 - mean_squared_error: 0.0315 - val_loss: 0.0360 - val_mean_squared_error: 0.0360\n",
      "Epoch 45/50\n",
      "6s - loss: 0.0314 - mean_squared_error: 0.0314 - val_loss: 0.0361 - val_mean_squared_error: 0.0361\n",
      "Epoch 46/50\n",
      "6s - loss: 0.0314 - mean_squared_error: 0.0314 - val_loss: 0.0357 - val_mean_squared_error: 0.0357\n",
      "Epoch 47/50\n",
      "6s - loss: 0.0313 - mean_squared_error: 0.0313 - val_loss: 0.0362 - val_mean_squared_error: 0.0362\n",
      "Epoch 48/50\n",
      "6s - loss: 0.0313 - mean_squared_error: 0.0313 - val_loss: 0.0358 - val_mean_squared_error: 0.0358\n",
      "Epoch 49/50\n",
      "6s - loss: 0.0312 - mean_squared_error: 0.0312 - val_loss: 0.0362 - val_mean_squared_error: 0.0362\n",
      "Epoch 50/50\n",
      "6s - loss: 0.0311 - mean_squared_error: 0.0311 - val_loss: 0.0361 - val_mean_squared_error: 0.0361\n",
      "Evaluating model...\n",
      "65152/66088 [============================>.] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bTraining score mean_squared_error: 0.0307\n",
      "15296/16523 [==========================>...] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bTesting score mean_squared_error: 0.0361\n",
      "66088/66088 [==============================] - 2s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "16512/16523 [============================>.] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    }
   ],
   "source": [
    "if not is_model_trained:\n",
    "    print(\"Creating MLP model...\")\n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=512, input_shape=(input_dim, )))\n",
    "    model.add(Activation('relu'))\n",
    "    if use_dropout:\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=512))\n",
    "    if use_sigmoid_final_layer:\n",
    "        model.add(Activation('sigmoid'))\n",
    "    else:\n",
    "        model.add(Activation('relu'))\n",
    "    if use_dropout:\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=output_dim))\n",
    "\n",
    "    # Print model summary\n",
    "    print(\"Model summary:\")\n",
    "    print(model.summary())\n",
    "\n",
    "    # Compile model\n",
    "    print(\"Compiling model...\")\n",
    "    adam_optimizer = optimizers.Adam(lr=0.0005) # Default lr = 0.001\n",
    "    model.compile(loss=loss_function, optimizer=adam_optimizer, metrics=[loss_function])\n",
    "\n",
    "    # Fit the model\n",
    "    print(\"Fitting model...\")\n",
    "    model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=num_epochs, batch_size=batch_size, verbose=2)\n",
    "\n",
    "    # evaluate the model\n",
    "    print(\"Evaluating model...\")\n",
    "    scores = model.evaluate(X_train, Y_train, batch_size=batch_size)\n",
    "    print(\"Training score %s: %.4f\" % (model.metrics_names[1], scores[1]))\n",
    "    scores = model.evaluate(X_test, Y_test, batch_size=batch_size)\n",
    "    print(\"Testing score %s: %.4f\" % (model.metrics_names[1], scores[1]))\n",
    "    is_model_trained = True\n",
    "\n",
    "    #%% Save model\n",
    "    save_model_info(experiment_name, model)\n",
    "else:\n",
    "    model_path = os.path.join('models/', experiment_name + '.h5')\n",
    "    print(\"Model was already trained, instead loading: \" + model_path)\n",
    "    model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16448/16523 [============================>.] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    }
   ],
   "source": [
    "save_model_info(experiment_name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Produce predictions\n",
    "Y_test_pred = model.predict(X_test, batch_size=batch_size)\n",
    "\n",
    "# Reshape predictions to a 2d image and denormalize data\n",
    "Y_test_pred = denormalize_data(Y_test_pred)\n",
    "num_rows = Y_test_pred.shape[0]\n",
    "Y_test_pred_2d = np.reshape(Y_test_pred, (num_rows, 32, 32, 3))\n",
    "\n",
    "# Denormalize all datasets\n",
    "Dataset.denormalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new directory to save predictions results: predictions/assets/exp_arch-mlp_loss-mse_activation-sigmoid_epochs-50\n",
      "Saving results as html to: predictions/results_exp_arch-mlp_loss-mse_activation-sigmoid_epochs-50.html\n"
     ]
    }
   ],
   "source": [
    "### Save predictions to disk\n",
    "save_predictions_info(experiment_name, Y_test_pred_2d, id_test, Dataset, num_images=50)\n",
    "print_results_as_html(experiment_name, Y_test_pred_2d, Dataset, num_images=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[100 157 199]\n",
      "  [102 158 199]\n",
      "  [108 161 203]\n",
      "  ..., \n",
      "  [112 154 203]\n",
      "  [121 164 213]\n",
      "  [128 171 219]]\n",
      "\n",
      " [[112 165 208]\n",
      "  [112 165 207]\n",
      "  [115 168 208]\n",
      "  ..., \n",
      "  [121 163 212]\n",
      "  [129 172 220]\n",
      "  [138 180 228]]\n",
      "\n",
      " [[118 171 213]\n",
      "  [118 171 213]\n",
      "  [119 172 214]\n",
      "  ..., \n",
      "  [120 163 211]\n",
      "  [130 172 220]\n",
      "  [142 183 229]]\n",
      "\n",
      " ..., \n",
      " [[ 33  67 101]\n",
      "  [ 33  67 101]\n",
      "  [ 31  63  97]\n",
      "  ..., \n",
      "  [131 178 232]\n",
      "  [130 178 233]\n",
      "  [129 176 231]]\n",
      "\n",
      " [[ 21  54  89]\n",
      "  [ 20  53  88]\n",
      "  [ 20  53  87]\n",
      "  ..., \n",
      "  [135 181 236]\n",
      "  [136 181 236]\n",
      "  [135 180 236]]\n",
      "\n",
      " [[ 10  42  78]\n",
      "  [  6  38  73]\n",
      "  [  5  37  72]\n",
      "  ..., \n",
      "  [145 191 247]\n",
      "  [143 189 244]\n",
      "  [139 184 239]]]\n",
      "[[[107 159 209]\n",
      "  [108 160 210]\n",
      "  [109 161 211]\n",
      "  ..., \n",
      "  [109 162 212]\n",
      "  [109 162 212]\n",
      "  [109 162 212]]\n",
      "\n",
      " [[108 160 210]\n",
      "  [108 160 210]\n",
      "  [109 161 211]\n",
      "  ..., \n",
      "  [110 163 213]\n",
      "  [109 162 212]\n",
      "  [109 162 212]]\n",
      "\n",
      " [[109 161 211]\n",
      "  [109 161 211]\n",
      "  [110 162 212]\n",
      "  ..., \n",
      "  [110 163 213]\n",
      "  [110 163 213]\n",
      "  [110 163 213]]\n",
      "\n",
      " ..., \n",
      " [[  8   6  11]\n",
      "  [  9   7  10]\n",
      "  [  9   5   6]\n",
      "  ..., \n",
      "  [106 131 162]\n",
      "  [108 131 162]\n",
      "  [106 127 156]]\n",
      "\n",
      " [[  3   0   7]\n",
      "  [  9   7  12]\n",
      "  [  7   2   6]\n",
      "  ..., \n",
      "  [ 99 122 153]\n",
      "  [104 125 154]\n",
      "  [103 123 150]]\n",
      "\n",
      " [[  4   1   8]\n",
      "  [ 21  19  24]\n",
      "  [ 19  14  18]\n",
      "  ..., \n",
      "  [102 123 152]\n",
      "  [100 120 147]\n",
      "  [ 96 113 141]]]\n",
      "[[[113 173 225]\n",
      "  [116 172 223]\n",
      "  [118 172 219]\n",
      "  ..., \n",
      "  [123 173 222]\n",
      "  [106 167 224]\n",
      "  [107 173 234]]\n",
      "\n",
      " [[113 173 225]\n",
      "  [116 172 223]\n",
      "  [118 172 219]\n",
      "  ..., \n",
      "  [118 166 214]\n",
      "  [119 176 231]\n",
      "  [108 170 229]]\n",
      "\n",
      " [[113 173 225]\n",
      "  [116 172 223]\n",
      "  [118 172 219]\n",
      "  ..., \n",
      "  [131 174 217]\n",
      "  [122 175 225]\n",
      "  [108 168 222]]\n",
      "\n",
      " ..., \n",
      " [[ 29  21  19]\n",
      "  [  7   0   0]\n",
      "  [ 21  10   8]\n",
      "  ..., \n",
      "  [132 181 224]\n",
      "  [133 180 222]\n",
      "  [133 180 222]]\n",
      "\n",
      " [[ 40  27  21]\n",
      "  [ 16   3   0]\n",
      "  [ 40  27  21]\n",
      "  ..., \n",
      "  [135 180 222]\n",
      "  [136 179 221]\n",
      "  [136 180 219]]\n",
      "\n",
      " [[ 46  31  24]\n",
      "  [ 36  21  14]\n",
      "  [ 56  41  34]\n",
      "  ..., \n",
      "  [135 180 221]\n",
      "  [136 180 219]\n",
      "  [137 179 217]]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test_pred_2d[0])\n",
    "print(Dataset.images_outer2d[id_test[0]])\n",
    "print(Dataset.images_inner2d[id_test[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Image.fromarray(Y_test_pred_2d[0]).save(\"a.jpg\")\n",
    "#Image.fromarray(Y_test_pred_2d[0]).save(\"a.bmp\")\n",
    "#Image.fromarray(Y_test_pred_2d[1]).save(\"aa.jpg\")\n",
    "#Image.fromarray(Y_test_pred_2d[1]).save(\"aa.bmp\")\n",
    "#Image.fromarray(Dataset.images_outer2d[id_test[0]]).save(\"b.jpg\")\n",
    "#Image.fromarray(Dataset.images_inner2d[id_test[0]]).save(\"c.jpg\")\n",
    "#Image.fromarray(Dataset.images[id_test[0]]).save(\"d.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
