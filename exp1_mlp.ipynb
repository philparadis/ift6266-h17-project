{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Mar 15 14:54:01 2017\n",
    "\n",
    "@author: paradiph\n",
    "\"\"\"\n",
    "\n",
    "import os, sys\n",
    "import glob\n",
    "import cPickle as pkl\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "#from skimage.transform import resize\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras.utils import plot_model\n",
    "\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Run experiments here\n",
    "# Define your global options and experiment name\n",
    "# Then run the desired model\n",
    "#################################################\n",
    "\n",
    "### The experiment name is very important.\n",
    "\n",
    "## Your model will be saved in:                           models/<experiment_name>.h5\n",
    "## A summary of your model architecture will saved be in: models/summary_<experiment_name>.txt\n",
    "## Your model's performance will be saved in:             models/performance_<experiment_name>.txt\n",
    "\n",
    "## Your predictions will be saved in: predictions/<experiment_name>/assets/Y_pred_<i>.jpg\n",
    "##                                    predictions/<experiment_name>/assets/Y_<i>.jpg\n",
    "##                                    predictions/<experiment_name>/assets/X_outer_<i>.jpg\n",
    "##                                    predictions/<experiment_name>/assets/X_full_<i>.jpg\n",
    "##                                    predictions/<experiment_name>/assets/X_full_pred_<i>.jpg\n",
    "\n",
    "#experiment_name = \"exp1_mlp_mse_dropout\"\n",
    "experiment_name = \"exp2_mlp_mse_nodropout\"\n",
    "#experiment_name = \"exp3_mlp_mse_sigmoid_final_layer\"\n",
    "#TODO: Which ever first 3 experiments work best, repeat it with msa instead of mse. i.e. experiment_name = \"exp4_mlp_msa_sigmoid_final_layer\"\n",
    "batch_size = 64\n",
    "num_epochs = 25\n",
    "loss_function = 'mse'\n",
    "use_dropout = False\n",
    "use_sigmoid_final_layer = False\n",
    "\n",
    "### Fixed variables: DO NOT CHANGE THOSE\n",
    "input_dim = 64*64*3 - 32*32*3\n",
    "output_dim = 32*32*3\n",
    "path_mscoco=\"datasets/mscoco_inpainting/inpainting/\"\n",
    "path_traindata=\"train2014\"\n",
    "path_caption_dict=\"dict_key_imgID_value_caps_train_and_valid.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### State variables: DO NOT EDIT\n",
    "### ONLY RUN THIS CELL IF YOU WANNA RESET EVERYTHING AND RELOAD THE DATA, RETRAIN THE MODEL, ETC.\n",
    "\n",
    "is_dataset_loaded = False\n",
    "is_model_trained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "# Info about the dataset\n",
    "#######################################\n",
    "# The data is already split into training and validation datasets\n",
    "# The training dataset has:\n",
    "# - 82782 items\n",
    "# - 984 MB of data\n",
    "# The validation dataset has:\n",
    "# - 40504 items\n",
    "# - 481 MB of data\n",
    "#\n",
    "# There is also a pickled dictionary that maps image filenames (minutes the\n",
    "# .jpg extension) to a list of 5 strings (the 5 human-generated captions).\n",
    "# This dictionary is an OrderedDict with 123286 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Utilities functions\n",
    "\n",
    "## Your model will be saved in:                           models/<experiment_name>.h5\n",
    "## A summary of your model architecture will saved be in: models/summary_<experiment_name>.txt\n",
    "## Your model's performance will be saved in:             models/performance_<experiment_name>.txt\n",
    "def save_model_info(exp_name, model):\n",
    "    out_dir = \"models/\"\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "        \n",
    "    model.save(os.path.join(out_dir, exp_name + '.h5')) \n",
    "    \n",
    "    #TODO: INSTALL pydot\n",
    "    #plot_model(model, to_file=os.path.join('model/', 'architecture_' + exp_name + '.png'), show_shapes=True)\n",
    "    \n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = open(os.path.join(out_dir, 'summary_' + exp_name + '.txt'), 'w')\n",
    "    model.summary()\n",
    "    sys.stdout = old_stdout\n",
    "\n",
    "    with open(os.path.join(out_dir, 'performance_' + exp_name + '.txt'), 'w') as fd:\n",
    "        # evaluate the model\n",
    "        scores = model.evaluate(X_train, Y_train, batch_size=batch_size)\n",
    "        fd.write(\"Training score %s: %.4f\\n\" % (model.metrics_names[1], scores[1]))\n",
    "        scores = model.evaluate(X_test, Y_test, batch_size=batch_size)\n",
    "        fd.write(\"Testing score %s: %.4f\\n\" % (model.metrics_names[1], scores[1]))\n",
    "        \n",
    "## Your predictions will be saved in: predictions/<experiment_name>/Y_pred_<i>.jpg\n",
    "##                                    predictions/<experiment_name>/Y_<i>.jpg\n",
    "##                                    predictions/<experiment_name>/X_outer_<i>.jpg\n",
    "##                                    predictions/<experiment_name>/X_full_<i>.jpg\n",
    "##                                    predictions/<experiment_name>/X_full_pred_<i>.jpg\n",
    "def save_predictions_info(exp_name, pred, pred_indices, dataset,\n",
    "                          num_images = 10, show_images = False, use_flattened_datasets = True):\n",
    "    if use_flattened_datasets:\n",
    "        out_dir = os.path.join('predictions/', exp_name, \"assets/\")\n",
    "        if not os.path.exists(out_dir):\n",
    "            print(\"Creating new directory to save predictions results: \" + out_dir)\n",
    "            os.makedirs(out_dir)\n",
    "        else:\n",
    "            print(\"Overwriting previously saved prediction results in directory: \" + out_dir)\n",
    "            \n",
    "    for row in range(num_images):\n",
    "        idt = pred_indices[row]\n",
    "        img = Image.fromarray(dataset.images_outer2d[idt])\n",
    "        img.show()\n",
    "        img.save(os.path.join(out_dir, 'images_outer2d_' + str(row) + '.jpg'))\n",
    "\n",
    "        img = Image.fromarray(pred[row])\n",
    "        img.show()\n",
    "        img.save(os.path.join(out_dir, 'images_pred_' + str(row) + '.jpg'))\n",
    "\n",
    "        img = Image.fromarray(dataset.images_inner2d[idt])\n",
    "        img.show()\n",
    "        img.save(os.path.join(out_dir, 'images_inner2d_' + str(row) + '.jpg'))\n",
    "\n",
    "        fullimg = Image.fromarray(dataset.images[idt])\n",
    "        fullimg.show()\n",
    "        fullimg.save(os.path.join(out_dir, 'fullimages_' + str(row) + '.jpg'))\n",
    "\n",
    "        fullimg_pred = np.copy(dataset.images[idt])\n",
    "        center = (int(np.floor(fullimg_pred.shape[0] / 2.)), int(np.floor(fullimg_pred.shape[1] / 2.)))\n",
    "        fullimg_pred[center[0]-16:center[0]+16, center[1]-16:center[1]+16, :] = pred[row, :, :, :]\n",
    "        img = Image.fromarray(fullimg_pred)\n",
    "        img.show()\n",
    "        img.save(os.path.join(out_dir, 'fullimages_pred_' + str(row) + '.jpg'))\n",
    "\n",
    "def print_results_as_html(exp_name, pred, dataset, num_images=10):    \n",
    "    out_dir = os.path.join(\"predictions/\", exp_name)\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    path_html = os.path.join(out_dir, \"results.html\")\n",
    "    print(\"Saving results as html to: \" + path_html)\n",
    "\n",
    "    with open(path_html, 'w') as fd:\n",
    "        fd.write(\"\"\"\n",
    "<table style=\"width:150px\">\n",
    "  <tr>\n",
    "    <th>Input (outer frame)</th>\n",
    "    <th>Model prediction (inner frame)</th>\n",
    "    <th>Correct output (inner frame)</th> \n",
    "    <th>Input + prediction</th>\n",
    "    <th>Input + correct output)</th>\n",
    "  </tr>\n",
    "\"\"\")\n",
    "\n",
    "        for row in range(num_images):\n",
    "            fd.write(\"  <tr>\\n\")\n",
    "            fd.write('    <td><img src=\"assets/images_outer2d_' + str(row) + '.jpg\" width=\"128\" height=\"128\"></td>\\n')\n",
    "            fd.write('    <td><img src=\"assets/images_pred_' + str(row) + '.jpg\" width=\"64\" height=\"64\"></td>\\n')\n",
    "            fd.write('    <td><img src=\"assets/images_inner2d_' + str(row) + '.jpg\" width=\"64\" height=\"64\"></td>\\n')\n",
    "            fd.write('    <td><img src=\"assets/fullimages_pred_' + str(row) + '.jpg\" width=\"128\" height=\"128\"></td>\\n')\n",
    "            fd.write('    <td><img src=\"assets/fullimages_' + str(row) + '.jpg\" width=\"128\" height=\"128\"></td>\\n')\n",
    "            fd.write('</tr>\\n')\n",
    "                  \n",
    "\n",
    "def normalize_data(data):\n",
    "    data = data.astype('float32')\n",
    "    data /= 255\n",
    "    return data\n",
    "\n",
    "def denormalize_data(data):\n",
    "    data *= 255\n",
    "    data = data.astype('uint8')\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Define the main class for handling our dataset called InpaintingDataset\n",
    "\n",
    "class InpaintingDataset(object):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.images = []\n",
    "        self.images_outer2d = []\n",
    "        self.images_inner2d = []\n",
    "        self.images_outer_flat = []\n",
    "        self.images_inner_flat = []\n",
    "        self.captions_ids = []\n",
    "        self.captions_dict = []\n",
    "        self._is_dataset_loaded = False\n",
    "        self._is_flattened = False\n",
    "        self._is_normalized = False\n",
    "        self._num_rows = None\n",
    "    \n",
    "    def normalize(self):\n",
    "        if self._is_normalized:\n",
    "            print(\"WARNING: Attempting to normalize already normalized dataset... Ignoring this call...\")\n",
    "            return\n",
    "        self.images_outer_flat = normalize_data(self.images_outer_flat)\n",
    "        self.images_inner_flat = normalize_data(self.images_inner_flat)\n",
    "        self._is_normalized = True\n",
    "\n",
    "    def denormalize(self):\n",
    "        if not self._is_normalized:\n",
    "            print(\"WARNING: Attempting to denormalize already denormalized dataset... Ignoring this call...\")\n",
    "            return\n",
    "        self.images_outer_flat = denormalize_data(self.images_outer_flat)\n",
    "        self.images_inner_flat = denormalize_data(self.images_inner_flat)\n",
    "        self._is_normalized = False\n",
    "    \n",
    "    def load_jpgs_and_captions_and_flatten(self, paths_list, caption_path, force_reload = False):\n",
    "        with open(caption_path) as fd:\n",
    "            caption_dict = pkl.load(fd)\n",
    "        if not self._is_dataset_loaded and not force_reload:\n",
    "            images = []\n",
    "            images_outer2d = []\n",
    "            images_inner2d = []\n",
    "            images_outer_flat = []\n",
    "            images_inner_flat = []\n",
    "            captions_ids = []\n",
    "            captions_dict = []\n",
    "            for i, img_path in enumerate(paths_list):\n",
    "                img = Image.open(img_path)\n",
    "                img_array = np.array(img)\n",
    "\n",
    "                # File names look like this: COCO_train2014_000000520978.jpg\n",
    "                cap_id = os.path.basename(img_path)[:-4]\n",
    "\n",
    "                ### Get input/target from the images\n",
    "                center = (int(np.floor(img_array.shape[0] / 2.)), int(np.floor(img_array.shape[1] / 2.)))\n",
    "                if len(img_array.shape) == 3:\n",
    "                    image = np.copy(img_array)\n",
    "\n",
    "                    outer_2d = np.copy(img_array)\n",
    "                    outer_2d[center[0]-16:center[0]+16, center[1]-16:center[1]+16, :] = 0\n",
    "\n",
    "                    outer = np.copy(img_array)\n",
    "                    outer_mask = np.array(np.ones(np.shape(img_array)), dtype='bool')\n",
    "                    outer_mask[center[0]-16:center[0]+16, center[1]-16:center[1]+16, :] = False\n",
    "                    outer_flat = outer.flatten()\n",
    "                    outer_mask_flat = outer_mask.flatten()\n",
    "                    outer_flat = outer_flat[outer_mask_flat]\n",
    "\n",
    "                    inner2d = np.copy(img_array)\n",
    "                    inner2d = inner2d[center[0]-16:center[0]+16, center[1] - 16:center[1]+16, :]\n",
    "\n",
    "                    inner = np.copy(img_array)\n",
    "                    inner = inner[center[0]-16:center[0]+16, center[1] - 16:center[1]+16, :]\n",
    "                    inner_flat = inner.flatten()\n",
    "                else:\n",
    "                    # For now, ignore greyscale images\n",
    "                    continue\n",
    "                    #X_outer = np.copy(img_array)\n",
    "                    #X_outer[center[0]-16:center[0]+16, center[1]-16:center[1]+16] = 0\n",
    "                    #X_inner = img_array[center[0]-16:center[0]+16, center[1] - 16:center[1]+16]\n",
    "\n",
    "\n",
    "                #Image.fromarray(img_array).show()\n",
    "                images.append(image)\n",
    "                images_outer2d.append(outer_2d)\n",
    "                images_inner2d.append(inner2d)\n",
    "                images_outer_flat.append(outer_flat)\n",
    "                images_inner_flat.append(inner_flat)\n",
    "                captions_ids.append(cap_id)\n",
    "                captions_dict.append(caption_dict[cap_id])\n",
    "\n",
    "            self.images = np.array(images)\n",
    "            self.images_inner_flat = np.array(images_inner_flat)\n",
    "            self.images_outer_flat = np.array(images_outer_flat)\n",
    "            self.images_outer2d = np.array(images_outer2d)\n",
    "            self.images_inner2d = np.array(images_inner2d)\n",
    "            self.captions_ids = np.array(captions_ids)\n",
    "            self.captions_dict = np.array(captions_dict)\n",
    "\n",
    "            self._is_flattened = True\n",
    "            self._is_dataset_loaded = True\n",
    "            self._num_rows = self.images.shape[0]\n",
    "        else:\n",
    "            print(\"Dataset is already loaded. Skipping this call. Please pass the argument force_reload=True to force reloading of dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Create and initialize an empty InpaintingDataset object\n",
    "Dataset = InpaintingDataset(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: datasets/mscoco_inpainting/inpainting/train2014/*.jpg\n",
      "Finished loading and pre-processing datasets...\n",
      "Summary of datasets:\n",
      "images.shape            = (82611, 64, 64, 3)\n",
      "images_outer2d.shape    = (82611, 64, 64, 3)\n",
      "images_inner2d.shape    = (82611, 32, 32, 3)\n",
      "images_outer_flat.shape = (82611, 9216)\n",
      "images_inner_flat.shape = (82611, 3072)\n",
      "captions_ids.shape      = (82611,)\n",
      "captions_dict.shape     = (82611,)\n"
     ]
    }
   ],
   "source": [
    "### Load training images and captions\n",
    "\n",
    "# Get captions dictionary path\n",
    "caption_path = os.path.join(mscoco, dict_key_captions)\n",
    "    \n",
    "# Get a list of all training images full filename paths\n",
    "data_path = os.path.join(path_mscoco, path_traindata)\n",
    "print(\"Loading images from: \" + data_path + \"/*.jpg\")\n",
    "train_images_paths = glob.glob(data_path + \"/*.jpg\")\n",
    "Dataset.load_jpgs_and_captions_and_flatten(train_images_paths, caption_path)\n",
    "\n",
    "print(\"Finished loading and pre-processing datasets...\")\n",
    "print(\"Summary of datasets:\")\n",
    "print(\"images.shape            = \" + str(Dataset.images.shape))\n",
    "print(\"images_outer2d.shape    = \" + str(Dataset.images_outer2d.shape))\n",
    "print(\"images_inner2d.shape    = \" + str(Dataset.images_inner2d.shape))\n",
    "print(\"images_outer_flat.shape = \" + str(Dataset.images_outer_flat.shape))\n",
    "print(\"images_inner_flat.shape = \" + str(Dataset.images_inner_flat.shape))\n",
    "print(\"captions_ids.shape      = \" + str(Dataset.captions_ids.shape))\n",
    "print(\"captions_dict.shape     = \" + str(Dataset.captions_dict.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing sanity check using first 10 elements of first 3 rows:\n",
      "[57 69 57 65 79 56 63 81 43 53]\n",
      "Row 0 passed sanity check!\n",
      "[197 202 195 167 164 147 104  87  57 102]\n",
      "Row 1 passed sanity check!\n",
      "[104 100  97  77  80  53 172 181 128 242]\n",
      "Row 2 passed sanity check!\n"
     ]
    }
   ],
   "source": [
    "### Sanity check:\n",
    "print(\"Performing sanity check using first 10 elements of first 3 rows:\")\n",
    "sanity_check_values = np.array([[57,   69,  57,  65,  79,  56,  63,  81,  43,  53],\n",
    "                                [197, 202, 195, 167, 164, 147, 104,  87,  57, 102],\n",
    "                                [104, 100,  97,  77,  80,  53, 172, 181, 128, 242]])\n",
    "for i in range(3):\n",
    "    top10 = Dataset.images_inner_flat[i, range(10)]\n",
    "    print(top10)\n",
    "    np.testing.assert_array_equal(top10, sanity_check_values[i])\n",
    "    print(\"Row \" + str(i) + \" passed sanity check!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset into training and testing sets with shuffling...\n",
      "Splitting dataset into training and testing sets with shuffling...\n",
      "X_train.shape = (66088, 9216)\n",
      "X_test.shape  = (16523, 9216)\n",
      "Y_train.shape = (66088, 3072)\n",
      "Y_test.shape  = (16523, 3072)\n",
      "id_train.shape = (66088,)\n",
      "id_test.shape  = (16523,)\n"
     ]
    }
   ],
   "source": [
    "### Normalize datasets\n",
    "Dataset.normalize()\n",
    "\n",
    "### Split into training and testing data\n",
    "from sklearn.cross_validation import train_test_split\n",
    "num_rows = Dataset.images.shape[0]\n",
    "indices = np.arange(num_rows)\n",
    "id_train, id_test = train_test_split(indices,\n",
    "                                     test_size=0.20,\n",
    "                                     random_state=1)\n",
    "\n",
    "### Generating the training and testing datasets (80%/20% train/test split)\n",
    "print(\"Splitting dataset into training and testing sets with shuffling...\")\n",
    "X_train, X_test, Y_train, Y_test = Dataset.images_outer_flat[id_train], \\\n",
    "                                   Dataset.images_outer_flat[id_test], \\\n",
    "                                   Dataset.images_inner_flat[id_train], \\\n",
    "                                   Dataset.images_inner_flat[id_test]\n",
    "\n",
    "print(\"Splitting dataset into training and testing sets with shuffling...\")\n",
    "print(\"X_train.shape = \" + str(X_train.shape))\n",
    "print(\"X_test.shape  = \" + str(X_test.shape))\n",
    "print(\"Y_train.shape = \" + str(Y_train.shape))\n",
    "print(\"Y_test.shape  = \" + str(Y_test.shape))\n",
    "print(\"id_train.shape = \" + str(id_train.shape))\n",
    "print(\"id_test.shape  = \" + str(id_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_train = [17442 21862  2835 ..., 50057  5192 77708]\n",
      "id_test  = [40977 36857 38411 ..., 77626 38615 14749]\n",
      "Y_train.shape = (66088, 3072)\n",
      "Y_train[0,1500:1550] = \n",
      "[ 0.48235294  0.45882353  0.46666667  0.38039216  0.37254903  0.42352942\n",
      "  0.41176471  0.40784314  0.47843137  0.43137255  0.43529412  0.51764709\n",
      "  0.3882353   0.40000001  0.47450981  0.51372552  0.52156866  0.58039218\n",
      "  0.53725493  0.53725493  0.57647061  0.29803923  0.28627452  0.3137255\n",
      "  0.40392157  0.38431373  0.40784314  0.45490196  0.41960785  0.43921569\n",
      "  0.33333334  0.28235295  0.30980393  0.33333334  0.28235295  0.31764707\n",
      "  0.38431373  0.40392157  0.5529412   0.32941177  0.34509805  0.48235294\n",
      "  0.35686275  0.37254903  0.47843137  0.33725491  0.33333334  0.39607844\n",
      "  0.33333334  0.32549021]\n"
     ]
    }
   ],
   "source": [
    "### Sanity check:\n",
    "print(\"id_train = \" + str(id_train))\n",
    "print(\"id_test  = \" + str(id_test))\n",
    "print(\"Y_train.shape = \" + str(Y_train.shape))\n",
    "print(\"Y_train[0,1500:1550] = \\n\" + str(Y_train[0,1500:1550]))\n",
    "\n",
    "idx = id_train[0]\n",
    "img = Image.fromarray(Dataset.images[0])\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_model_trained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MLP model...\n",
      "Model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 256)               2359552   \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 3072)              789504    \n",
      "=================================================================\n",
      "Total params: 3,214,848.0\n",
      "Trainable params: 3,214,848.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Compiling model...\n",
      "Fitting model...\n",
      "Train on 66088 samples, validate on 16523 samples\n",
      "Epoch 1/50\n",
      "6s - loss: 0.0576 - mean_squared_error: 0.0576 - val_loss: 0.0429 - val_mean_squared_error: 0.0429\n",
      "Epoch 2/50\n",
      "6s - loss: 0.0414 - mean_squared_error: 0.0414 - val_loss: 0.0405 - val_mean_squared_error: 0.0405\n",
      "Epoch 3/50\n",
      "6s - loss: 0.0395 - mean_squared_error: 0.0395 - val_loss: 0.0389 - val_mean_squared_error: 0.0389\n",
      "Epoch 4/50\n",
      "6s - loss: 0.0383 - mean_squared_error: 0.0383 - val_loss: 0.0383 - val_mean_squared_error: 0.0383\n",
      "Epoch 5/50\n",
      "6s - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0373 - val_mean_squared_error: 0.0373\n",
      "Epoch 6/50\n",
      "6s - loss: 0.0369 - mean_squared_error: 0.0369 - val_loss: 0.0369 - val_mean_squared_error: 0.0369\n",
      "Epoch 7/50\n",
      "6s - loss: 0.0365 - mean_squared_error: 0.0365 - val_loss: 0.0367 - val_mean_squared_error: 0.0367\n",
      "Epoch 8/50\n",
      "6s - loss: 0.0361 - mean_squared_error: 0.0361 - val_loss: 0.0365 - val_mean_squared_error: 0.0365\n",
      "Epoch 9/50\n",
      "6s - loss: 0.0359 - mean_squared_error: 0.0359 - val_loss: 0.0362 - val_mean_squared_error: 0.0362\n",
      "Epoch 10/50\n",
      "6s - loss: 0.0356 - mean_squared_error: 0.0356 - val_loss: 0.0361 - val_mean_squared_error: 0.0361\n",
      "Epoch 11/50\n",
      "6s - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0359 - val_mean_squared_error: 0.0359\n",
      "Epoch 12/50\n",
      "6s - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0360 - val_mean_squared_error: 0.0360\n",
      "Epoch 13/50\n",
      "6s - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0354 - val_mean_squared_error: 0.0354\n",
      "Epoch 14/50\n",
      "6s - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.0356 - val_mean_squared_error: 0.0356\n",
      "Epoch 15/50\n",
      "6s - loss: 0.0348 - mean_squared_error: 0.0348 - val_loss: 0.0354 - val_mean_squared_error: 0.0354\n",
      "Epoch 16/50\n",
      "6s - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0352 - val_mean_squared_error: 0.0352\n",
      "Epoch 17/50\n",
      "6s - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0352 - val_mean_squared_error: 0.0352\n",
      "Epoch 18/50\n",
      "6s - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0352 - val_mean_squared_error: 0.0352\n",
      "Epoch 19/50\n",
      "6s - loss: 0.0343 - mean_squared_error: 0.0343 - val_loss: 0.0351 - val_mean_squared_error: 0.0351\n",
      "Epoch 20/50\n",
      "6s - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0349 - val_mean_squared_error: 0.0349\n",
      "Epoch 21/50\n",
      "6s - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0352 - val_mean_squared_error: 0.0352\n",
      "Epoch 22/50\n",
      "6s - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0350 - val_mean_squared_error: 0.0350\n",
      "Epoch 23/50\n",
      "6s - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.0351 - val_mean_squared_error: 0.0351\n",
      "Epoch 24/50\n",
      "6s - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0349 - val_mean_squared_error: 0.0349\n",
      "Epoch 25/50\n",
      "6s - loss: 0.0337 - mean_squared_error: 0.0337 - val_loss: 0.0347 - val_mean_squared_error: 0.0347\n",
      "Epoch 26/50\n",
      "6s - loss: 0.0336 - mean_squared_error: 0.0336 - val_loss: 0.0351 - val_mean_squared_error: 0.0351\n",
      "Epoch 27/50\n",
      "6s - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0347 - val_mean_squared_error: 0.0347\n",
      "Epoch 28/50\n",
      "6s - loss: 0.0334 - mean_squared_error: 0.0334 - val_loss: 0.0347 - val_mean_squared_error: 0.0347\n",
      "Epoch 29/50\n",
      "6s - loss: 0.0334 - mean_squared_error: 0.0334 - val_loss: 0.0347 - val_mean_squared_error: 0.0347\n",
      "Epoch 30/50\n",
      "6s - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0349 - val_mean_squared_error: 0.0349\n",
      "Epoch 31/50\n",
      "5s - loss: 0.0332 - mean_squared_error: 0.0332 - val_loss: 0.0349 - val_mean_squared_error: 0.0349\n",
      "Epoch 32/50\n"
     ]
    }
   ],
   "source": [
    "if not is_model_trained:\n",
    "    print(\"Creating MLP model...\")\n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=512, input_shape=(input_dim, )))\n",
    "    model.add(Activation('relu'))\n",
    "    if use_dropout:\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=512))\n",
    "    if use_sigmoid_final_layer:\n",
    "        model.add(Activation('sigmoid'))\n",
    "    else:\n",
    "        model.add(Activation('relu'))\n",
    "    if use_dropout:\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=output_dim))\n",
    "\n",
    "    # Print model summary\n",
    "    print(\"Model summary:\")\n",
    "    print(model.summary())\n",
    "\n",
    "    # Compile model\n",
    "    print(\"Compiling model...\")\n",
    "    adam_optimizer = optimizers.Adam(lr=0.0005) # Default lr = 0.001\n",
    "    model.compile(loss=loss_function, optimizer=adam_optimizer, metrics=[loss_function])\n",
    "\n",
    "    # Fit the model\n",
    "    print(\"Fitting model...\")\n",
    "    model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=num_epochs, batch_size=batch_size, verbose=2)\n",
    "\n",
    "    # evaluate the model\n",
    "    print(\"Evaluating model...\")\n",
    "    scores = model.evaluate(X_train, Y_train, batch_size=batch_size)\n",
    "    print(\"Training score %s: %.2f\" % (model.metrics_names[1], scores[1]))\n",
    "    scores = model.evaluate(X_test, Y_test, batch_size=batch_size)\n",
    "    print(\"Testing score %s: %.2f\" % (model.metrics_names[1], scores[1]))\n",
    "    is_model_trained = True\n",
    "\n",
    "    #%% Save model\n",
    "    save_model_info(experiment_name, model)\n",
    "else:\n",
    "    model_path = os.path.join('models/', experiment_name + '.h5')\n",
    "    print(\"Model was already trained, instead loading: \" + model_path)\n",
    "    model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14976/16523 [==========================>...] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    }
   ],
   "source": [
    "save_model_info(experiment_name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Attempting to denormalize already denormalized dataset... Ignoring this call...\n"
     ]
    }
   ],
   "source": [
    "### Produce predictions\n",
    "Y_test_pred = model.predict(X_test, batch_size=batch_size)\n",
    "\n",
    "# Reshape predictions to a 2d image and denormalize data\n",
    "Y_test_pred = denormalize_data(Y_test_pred)\n",
    "num_rows = Y_test_pred.shape[0]\n",
    "Y_test_pred_2d = np.reshape(Y_test_pred, (num_rows, 32, 32, 3))\n",
    "\n",
    "# Denormalize all datasets\n",
    "Dataset.denormalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting previously saved prediction results in directory: predictions/exp2_mlp_mse_nodropout/assets/\n",
      "Saving results as html to: predictions/exp2_mlp_mse_nodropout/results.html\n"
     ]
    }
   ],
   "source": [
    "### Save predictions to disk\n",
    "save_predictions_info(experiment_name, Y_test_pred_2d, id_test, Dataset)\n",
    "print_results_as_html(experiment_name, Y_test_pred_2d, Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[125 118 198]\n",
      "  [ 77 107 110]\n",
      "  [158   8 182]\n",
      "  ..., \n",
      "  [152 141  63]\n",
      "  [255  22  27]\n",
      "  [ 20  39  83]]\n",
      "\n",
      " [[141 180  53]\n",
      "  [107 230 223]\n",
      "  [ 23 234  18]\n",
      "  ..., \n",
      "  [ 80  27 194]\n",
      "  [162  26 212]\n",
      "  [193 122 159]]\n",
      "\n",
      " [[220  59 140]\n",
      "  [163  84 205]\n",
      "  [206  82  20]\n",
      "  ..., \n",
      "  [227  27 223]\n",
      "  [137  40  91]\n",
      "  [254 251 113]]\n",
      "\n",
      " ..., \n",
      " [[150   8  22]\n",
      "  [ 88 198  74]\n",
      "  [ 12 162 184]\n",
      "  ..., \n",
      "  [253  41  45]\n",
      "  [222 246  82]\n",
      "  [ 27 119 187]]\n",
      "\n",
      " [[116 167 216]\n",
      "  [ 92 129 135]\n",
      "  [ 32 138 130]\n",
      "  ..., \n",
      "  [145 175  34]\n",
      "  [248  20 167]\n",
      "  [ 92 139 250]]\n",
      "\n",
      " [[131  88 192]\n",
      "  [236  19 120]\n",
      "  [149  77   1]\n",
      "  ..., \n",
      "  [ 22  62 153]\n",
      "  [209 253 188]\n",
      "  [ 54   7   0]]]\n",
      "[[[177 153 189]\n",
      "  [185 160 199]\n",
      "  [146 121 163]\n",
      "  ..., \n",
      "  [177 181 190]\n",
      "  [174 181 189]\n",
      "  [ 83  92  99]]\n",
      "\n",
      " [[177 153 187]\n",
      "  [172 147 186]\n",
      "  [160 135 175]\n",
      "  ..., \n",
      "  [195 202 210]\n",
      "  [208 217 224]\n",
      "  [131 140 147]]\n",
      "\n",
      " [[204 180 214]\n",
      "  [189 165 201]\n",
      "  [197 172 212]\n",
      "  ..., \n",
      "  [210 219 226]\n",
      "  [230 241 247]\n",
      "  [159 170 176]]\n",
      "\n",
      " ..., \n",
      " [[ 90  84  88]\n",
      "  [102  96 100]\n",
      "  [118 112 116]\n",
      "  ..., \n",
      "  [ 82  83  87]\n",
      "  [ 79  80  82]\n",
      "  [ 83  84  86]]\n",
      "\n",
      " [[104  98 102]\n",
      "  [105  99 103]\n",
      "  [107 101 105]\n",
      "  ..., \n",
      "  [142 140 143]\n",
      "  [138 134 135]\n",
      "  [107 103 104]]\n",
      "\n",
      " [[103  96 103]\n",
      "  [103  96 103]\n",
      "  [102  95 102]\n",
      "  ..., \n",
      "  [171 165 169]\n",
      "  [180 174 176]\n",
      "  [176 167 168]]]\n",
      "[[[163 158 164]\n",
      "  [109 107 112]\n",
      "  [ 80  79  85]\n",
      "  ..., \n",
      "  [146 155 160]\n",
      "  [ 90 100 102]\n",
      "  [ 80  90  92]]\n",
      "\n",
      " [[174 167 174]\n",
      "  [125 120 127]\n",
      "  [ 78  77  83]\n",
      "  ..., \n",
      "  [ 63  71  74]\n",
      "  [ 41  51  52]\n",
      "  [ 57  67  68]]\n",
      "\n",
      " [[141 131 140]\n",
      "  [121 113 124]\n",
      "  [ 88  85  94]\n",
      "  ..., \n",
      "  [ 31  40  39]\n",
      "  [ 26  36  35]\n",
      "  [ 63  73  72]]\n",
      "\n",
      " ..., \n",
      " [[181 177 192]\n",
      "  [201 197 212]\n",
      "  [207 203 218]\n",
      "  ..., \n",
      "  [129 162 167]\n",
      "  [130 148 158]\n",
      "  [180 179 195]]\n",
      "\n",
      " [[129 123 137]\n",
      "  [142 136 150]\n",
      "  [152 146 160]\n",
      "  ..., \n",
      "  [ 50  73  79]\n",
      "  [ 93 103 113]\n",
      "  [105  94 111]]\n",
      "\n",
      " [[100  92 105]\n",
      "  [ 98  90 105]\n",
      "  [ 95  87 102]\n",
      "  ..., \n",
      "  [ 33  52  59]\n",
      "  [102 106 118]\n",
      "  [ 88  73  92]]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test_pred_2d[0])\n",
    "print(Dataset.images_outer2d[id_test[0]])\n",
    "print(Dataset.images_inner2d[id_test[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Image.fromarray(Y_test_pred_2d[0]).save(\"a.jpg\")\n",
    "Image.fromarray(Dataset.images_outer2d[id_test[0]]).save(\"b.jpg\")\n",
    "Image.fromarray(Dataset.images_inner2d[id_test[0]]).save(\"c.jpg\")\n",
    "Image.fromarray(Dataset.images[id_test[0]]).save(\"d.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
